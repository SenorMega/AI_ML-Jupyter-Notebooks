{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a2fb5123ae5c455",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 13.4: Decision Boundaries with Two Variables\n",
    "\n",
    "**Expected Time = 60 minutes** \n",
    "\n",
    "**Total Points = 40** \n",
    "\n",
    "In the first examples, your work has utilized a straight vertical line as the decision boundary for logistic regression. This is what a decision boundary looks like with only one feature, however with two features the decision boundary becomes a linear function of the two inputs. In this activity, you will focus on generating functions for these boundaries and show strategies for visualizing these boundaries. \n",
    "\n",
    "#### Index\n",
    "\n",
    "  - [Problem 1](#-Problem-1)\n",
    "  - [Problem 2](#-Problem-2)\n",
    "  - [Problem 3](#-Problem-3)\n",
    "  - [Problem 4](#-Problem-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-180308aae7d2d7b0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Again, you will use the penguins data from seaborn.  This time, you will use two features -- `flipper_length_mm` and `bill_length_mm` to build a logistic model and visualize the decision boundary.  The data is loaded and visualized below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset('penguins').dropna()\n",
    "penguins = penguins.loc[(penguins['species'] == 'Adelie') | (penguins['species'] == 'Gentoo')]\n",
    "X = penguins.drop('species', axis = 1)[['flipper_length_mm', 'bill_length_mm']]\n",
    "y = np.where(penguins.species == 'Adelie', 0, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = penguins, x = 'flipper_length_mm', y = 'bill_length_mm', hue = 'species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61ccd016c98fc188",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### A Logistic Model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To get started, instantiate a `LogisticRegression` object as `log_reg` below and fit on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2a9e2edd23d53626",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "log_reg = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5edb70583e600596",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "log_reg_ = LogisticRegression().fit(X_train, y_train)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert type(log_reg) == type(log_reg_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e0354e412867e85",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Examining the coefficients\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, our sigma function looks like:\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$z = \\beta_0 + \\beta_1 * x_0 + \\beta_2 * x_1.$$\n",
    "\n",
    "Below, assign the coefficients and intercept to `beta_0`, `beta_1` and `beta_2` respectively as floats.  Note that $x_0$ is flipper length.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-de41271c6395179d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "beta_0 = ''\n",
    "beta_1 = ''\n",
    "beta_2 = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "beta_0 = float(log_reg.intercept_)\n",
    "beta_1 = float(log_reg.coef_[0][0])\n",
    "beta_2 = float(log_reg.coef_[0][1])\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(f'z = {beta_0: .2f} + {beta_1: .2f}x0 + {beta_2: .2f}x1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ba95f7318397f251",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "log_reg_ = LogisticRegression().fit(X_train, y_train)\n",
    "beta_0_ = float(log_reg_.intercept_)\n",
    "beta_1_ = float(log_reg_.coef_[0][0])\n",
    "beta_2_ = float(log_reg_.coef_[0][1])\n",
    "#\n",
    "#\n",
    "#\n",
    "assert beta_0 == beta_0_\n",
    "assert beta_1 == beta_1_\n",
    "assert beta_2 == beta_2_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-81c77c9e7339f736",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Visualizing the decision boundary\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "<center>\n",
    "    <img src = 'images/dboundary.png' />\n",
    "</center>\n",
    "\n",
    "\n",
    "There is both a brute force and more formal approach for visualizing the decision boundary.  What we won't do, is create a grid of points, use the model to make predictions for them, and plot colored regions according to their predicted value. \n",
    "\n",
    "Instead, with two variables we can directly solve for the linear function in terms of $x_0$ and $x_1$, and your $\\beta$'s. Upon doing so we find a linear function defined as: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8f4438af8e043b9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "$$y = -\\frac{\\beta_1}{\\beta_2} * x_0 - \\frac{\\beta_0}{\\beta_2}$$\n",
    "\n",
    "Complete the function `decision_boundary` below that takes in $x_0$ and returns the appropriate value for $y$ based on this formula.  Uncomment the plot to verify your results using the defined `x = np.linspace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e6d6568117a8e6b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "def decision_boundary(x0, beta_0, beta_1, beta_2):\n",
    "    '''\n",
    "    Function returns values for linear decision boundaries\n",
    "    in binary classification setting accoring to the formula\n",
    "    y = -beta_1/beta_2 * x0 - beta_0/beta_2\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x0: np.array\n",
    "        domain for evaluation of function\n",
    "        \n",
    "    beta_0: float\n",
    "         intercept from fit logistic model\n",
    "    beta_1: float\n",
    "        first coefficient from logistic model\n",
    "    beta_2: float\n",
    "        second coefficient from logistic model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        values of y\n",
    "    '''\n",
    "    return None\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "def decision_boundary(x0, beta_0, beta_1, beta_2):\n",
    "    return -(beta_1/beta_2)*x0 - beta_0/beta_2\n",
    "### END SOLUTION\n",
    "x = np.linspace(165, 240, 100)\n",
    "print(decision_boundary(x, beta_0, beta_1, beta_2)[0], decision_boundary(x, beta_0, beta_1, beta_2)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code for figure\n",
    "# x = np.linspace(165, 240, 100)\n",
    "# sns.scatterplot(data = penguins, x = 'flipper_length_mm', y = 'bill_length_mm', hue = 'species')\n",
    "# plt.plot(x, decision_boundary(x, beta_0, beta_1, beta_2), '--', color = 'black')\n",
    "# plt.ylim(25, 65)\n",
    "# plt.fill_between(x, decision_boundary(x, beta_0, beta_1, beta_2), alpha = 0.3, color = 'lightblue')\n",
    "# plt.fill_between(x, decision_boundary(x, beta_0, beta_1, beta_2), np.repeat(70, 100), alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6713f398a08b64d4",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "def decision_boundary_(x0, beta_0, beta_1, beta_2):\n",
    "    return -(beta_1/beta_2)*x0 - beta_0/beta_2\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(decision_boundary(x, beta_0, beta_1, beta_2),decision_boundary_(x, beta_0, beta_1, beta_2))\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-769e80a3f0f16a66",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Comparing regressors\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, fit a second regressor using the argument `C = 0.001`. Compare the decision boundary by using what you've seen earlier. How did the decision boundary change based on this?  The slope of the new decision boundary should either be more or less than the default settings.  Assign your answer as a string -- `greater than` or `less than` to `ans4` below. Remember that the slope is negative. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66dfc51fc45c7a0f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ans4 = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ans4 = 'less than'\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(ans4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d0c153c049b09fc1",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ans4_ = 'less than'\n",
    "#\n",
    "#\n",
    "#\n",
    "assert ans4 == ans4_\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
