{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models\n",
    "\n",
    "Now that you have seen a variety of models for regression and classification problems, it is good to step back and weigh the pros and cons of these options.  In the case of classification models, there are at least three things to consider:\n",
    "\n",
    "1. Is the model good at handling imbalanced classes?\n",
    "2. Does the model train quickly?\n",
    "3. Does the model yield interpretable results?\n",
    "\n",
    "Depending on your dataset and goals, the importance of these considerations will vary from project to project.  Your goal is to review our models to this point and discuss the pros and cons of each.  Two example datasets are offered as a way to offer two very different tasks where interpretability of the model may be of differing importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Task\n",
    "\n",
    "Your goal is to discuss the pros and cons of Logistic Regression, Decision Trees, KNN, and SVM for the tasks below.  Consider at least the three questions above and list any additional considerations you believe are important to determining the \"best\" model for the task.  Share your response with your peers on the class discussion board.  \n",
    "\n",
    "**TASK 1**: Predicting Customer Churn\n",
    "\n",
    "Suppose you are tasked with producing a model to predict customer churn.  Which of your classification models would you use and what are the pros and cons of this model for this task?  Be sure to consider interpretability, imbalnced classes, and the speed of training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import time \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor, LinearRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "def evaluate_model1(model,X_train,y_train,X_test,y_test):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    fit_time = time.time() - start_time\n",
    "    \n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    \n",
    "    return train_score, test_score, fit_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is loaded below.  Note that the handwritten digit data is already split into features and target (`digits`, `labels`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = pd.read_csv('data/telecom_churn.csv').dropna()\n",
    "churn = churn.drop(['State'],axis=1)\n",
    "#churn.head()\n",
    "\n",
    "categorical = ['International plan', 'Voice mail plan']\n",
    "numerical = churn.drop(columns=categorical).columns\n",
    "numerical = numerical.drop(['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Training Score  Test Score  Fit Time\n",
      "0  Logistic Regression        0.863545    0.859712  0.036906\n",
      "1        Decision Tree        1.000000    0.912470  0.041891\n",
      "2                  KNN        0.912765    0.887290  0.008976\n",
      "3                  SVM        0.935574    0.919664  0.136637\n"
     ]
    }
   ],
   "source": [
    "X = churn.drop('Churn', axis=1)\n",
    "y = churn['Churn'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical),\n",
    "        ('cat', OneHotEncoder(), categorical)\n",
    "    ])\n",
    "\n",
    "# Create Pipelines\n",
    "log_reg = make_pipeline(preprocessor, LogisticRegression(max_iter=10000))\n",
    "dec_tree = make_pipeline(preprocessor, DecisionTreeClassifier())\n",
    "knn = make_pipeline(preprocessor, KNeighborsClassifier())\n",
    "svm = make_pipeline(preprocessor, SVC())\n",
    "\n",
    "# Evaluating models\n",
    "lr_train_score, lr_test_score, lr_fit_time = evaluate_model1(log_reg,X_train,y_train,X_test,y_test)\n",
    "dt_train_score, dt_test_score, dt_fit_time = evaluate_model1(dec_tree,X_train,y_train,X_test,y_test)\n",
    "knn_train_score, knn_test_score, knn_fit_time = evaluate_model1(knn,X_train,y_train,X_test,y_test)\n",
    "svm_train_score, svm_test_score, svm_fit_time = evaluate_model1(svm,X_train,y_train,X_test,y_test)\n",
    "\n",
    "# Creating a results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'KNN', 'SVM'],\n",
    "    'Training Score': [lr_train_score, dt_train_score, knn_train_score, svm_train_score],\n",
    "    'Test Score': [lr_test_score, dt_test_score, knn_test_score, svm_test_score],\n",
    "    'Fit Time': [lr_fit_time, dt_fit_time, knn_fit_time, svm_fit_time]\n",
    "})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 2**: Recognizing Handwritten Digits\n",
    "\n",
    "Suppose you are tasked with training a model to recognize handwritten digits.  Which of your classifier would you use here and why?  Again, be sure to consider the balance of classes, speed of training, and importance of interpretability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Training Score  Test Score  Fit Time\n",
      "0  Logistic Regression        1.000000    0.973333  0.119295\n",
      "1        Decision Tree        1.000000    0.860000  0.014960\n",
      "2                  KNN        0.988864    0.993333  0.002517\n",
      "3                  SVM        0.996288    0.986667  0.038898\n"
     ]
    }
   ],
   "source": [
    "digits, labels = load_digits(return_X_y=True, as_frame=True)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(digits, labels, random_state = 42)\n",
    "\n",
    "\n",
    "# Evaluating models\n",
    "start_time = time.time()\n",
    "logreg2 = LogisticRegression(max_iter=10000).fit(X_train2,y_train2) #, y_train2, y_test2)\n",
    "logreg2_time = time.time() - start_time\n",
    "logreg2_train_score = logreg2.score(X_train2, y_train2)\n",
    "logreg2_test_score = logreg2.score(X_test2, y_test2)\n",
    "\n",
    "start_time = time.time()\n",
    "dectree2 = DecisionTreeClassifier().fit(X_train2,y_train2) #, y_train2, y_test2)\n",
    "dectree2_time = time.time() - start_time\n",
    "dectree2_train_score = dectree2.score(X_train2, y_train2)\n",
    "dectree2_test_score = dectree2.score(X_test2, y_test2)\n",
    "\n",
    "start_time = time.time()\n",
    "knn2 = KNeighborsClassifier().fit(X_train2,y_train2) #, y_train2, y_test2)\n",
    "knn2_time = time.time() - start_time\n",
    "knn2_train_score = knn2.score(X_train2, y_train2)\n",
    "knn2_test_score = knn2.score(X_test2, y_test2)\n",
    "\n",
    "start_time = time.time()\n",
    "svm2 = SVC().fit(X_train2,y_train2) #, y_train2, y_test2)\n",
    "svm2_time = time.time() - start_time\n",
    "svm2_train_score = svm2.score(X_train2, y_train2)\n",
    "svm2_test_score = svm2.score(X_test2, y_test2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Creating a results DataFrame\n",
    "results2 = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'KNN', 'SVM'],\n",
    "    'Training Score': [logreg2_train_score, dectree2_train_score, knn2_train_score, svm2_train_score],\n",
    "    'Test Score': [logreg2_test_score, dectree2_test_score, knn2_test_score, svm2_test_score],\n",
    "    'Fit Time': [logreg2_time, dectree2_time, knn2_time, svm2_time]\n",
    "})\n",
    "\n",
    "print(results2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
